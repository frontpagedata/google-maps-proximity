---
title: "Google Maps Ranking - Proximity Study"
author: "François Delavy for Rankings.io"
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    theme: paper
    highlight: kate
    # code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
editor_options: 
  chunk_output_type: console
---


<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
background-color: #D21D5C;
border-color: #D21D5C;
}

body {
font-family: FiraSans-Regular;
color: #444444;
font-size: 14px;
}

h1 {
font-weight: bold;
font-size: 28px;
}

h1.title {
font-size: 30px;
color: #D21D5C;
}

h2 {
font-size: 24px;
}

h3 {
font-size: 18px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.showtext = TRUE, dpi = 700,
                      echo = FALSE # hide code for now
)

knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",", small.mark = ",", scientific = F)
})

Sys.setlocale("LC_TIME", "C")
# extrafont::loadfonts(device = "win")
extrafont::loadfonts()

```


```{r prep}
# SETUP

## packages: remove or add your necessary packages

# required_packages <- c("tidyverse", "readxl", "ggthemes", "hrbrthemes", "extrafont", "plotly", "scales", "stringr", "gganimate", "here", "tidytext", "sentimentr", "scales", "DT", "here", "sm", "mblm", "glue", "fs", "knitr", "rmdformats", "janitor", "urltools", "colorspace", "pdftools", "showtext")

required_packages <- c("tidyverse", "extrafont", "here", "colorspace", "pdftools", "kableExtra", "ggrepel")

for(i in required_packages) { 
  if(!require(i, character.only = T)) {
    
    #  if package is not existing, install then load the package
    install.packages(i, dependencies = T)
    require(i, character.only = T)
  }
}


## save plots?
save <- TRUE
#save <- FALSE

## quality of png's
dpi <- 750

## font adjust; please adjust to client´s website
#extrafont::loadfonts(device = "win", quiet = TRUE)
#font_add_google("Montserrat", "Montserrat")
# font_add_google("Overpass", "Overpass")
# font_add_google("Overpass Mono", "Overpass Mono")



## theme updates; please adjust to client´s website
#theme_set(ggthemes::theme_clean(base_size = 15))
theme_set(ggthemes::theme_clean(base_size = 12, base_family = "FiraSans-Regular"))


theme_update(plot.margin = margin(30, 30, 30, 30),
             plot.background = element_rect(color = "white",
                                            fill = "white"),
             plot.title = element_text(size = 20,
                                       face = "bold",
                                       lineheight = 1.05,
                                       hjust = .5,
                                       margin = margin(10, 0, 25, 0)),
             plot.title.position = "plot",
             plot.subtitle = element_text(size = 16),
             plot.caption = element_text(color = "grey40",
                                         size = 9,
                                         margin = margin(20, 0, -20, 0)),
             plot.caption.position = "plot",
             axis.line.x = element_line(color = "black",
                                        size = .8),
             axis.line.y = element_line(color = "black",
                                        size = .8),
             axis.title.x = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(t = 20)),
             axis.title.y = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(r = 20)),
             axis.text = element_text(size = 11,
                                      color = "black",
                                      face = "bold"),
             axis.text.x = element_text(margin = margin(t = 10)),
             axis.text.y = element_text(margin = margin(r = 10)),
             axis.ticks = element_blank(),
             panel.grid.major.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.major.y = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.y = element_blank(),
             panel.spacing.x = unit(4, "lines"),
             panel.spacing.y = unit(2, "lines"),
             legend.position = "top",
             legend.title = element_text(family = "Montserrat",
                                         color = "black",
                                         size = 14,
                                         margin = margin(5, 0, 5, 0)),
             legend.text = element_text(family = "Montserrat",
                                        color = "black",
                                        size = 11,
                                        margin = margin(4.5, 4.5, 4.5, 4.5)),
             legend.background = element_rect(fill = NA,
                                              color = NA),
             legend.key = element_rect(color = NA, fill = NA),
             #legend.key.width = unit(5, "lines"),
             #legend.spacing.x = unit(.05, "pt"),
             #legend.spacing.y = unit(.55, "pt"),
             #legend.margin = margin(0, 0, 10, 0),
             strip.text = element_text(face = "bold",
                                       margin = margin(b = 10)))

my_theme <- function(){
  theme(
    # plot.margin = margin(30, 30, 30, 30),
    plot.background = element_rect(color = "white",
                                   fill = "white"),
    plot.title = element_text(size = 14),
    plot.title.position = "plot",
    plot.subtitle = element_text(size = 10),
    plot.caption = element_text(color = "grey40",
                                size = 9),
    plot.caption.position = "plot",
    axis.line.x = element_line(color = "black",
                               size = .8),
    axis.line.y = element_line(color = "black",
                               size = .8),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 9,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.y = element_blank(),
    panel.spacing.x = unit(2, "lines"),
    panel.spacing.y = unit(1, "lines")
  )
}

## theme settings for flipped plots
theme_flip <-
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_line(size = .6,
                                          color = "#eaeaea"))

## theme settings for maps
theme_map <- 
  theme_void(base_family = "Montserrat") +
  theme(legend.direction = "horizontal",
        legend.box = "horizontal",
        legend.margin = margin(10, 10, 10, 10),
        legend.title = element_text(size = 17, 
                                    face = "bold"),
        legend.text = element_text(color = "grey33",
                                   size = 12),
        plot.margin = margin(15, 5, 15, 5),
        plot.title = element_text(face = "bold",
                                  size = 20,
                                  hjust = .5,
                                  margin = margin(30, 0, 10, 0)),
        plot.subtitle = element_text(face = "bold",
                                     color = "grey33",
                                     size = 17,
                                     hjust = .5,
                                     margin = margin(10, 0, -30, 0)),
        plot.caption = element_text(size = 14,
                                    color = "grey33",
                                    hjust = .97,
                                    margin = margin(-30, 0, 0, 0)))

## numeric format for labels
num_format <- scales::format_format(big.mark = ",", small.mark = ",", scientific = F)

## main colors rankings.io
r_col <- "#D21D5C"

# to be updated if/when needed:
# bl_col <- "#00d188"
# bl_dark <- darken(bl_col, .3, space = "HLS")
# 
# ## colors + labels for interval stripes
# int_cols <- c("#bce2d5", "#79d8b6", bl_col, "#009f66", "#006c45", "#003925")
# int_perc <- c("100%", "95%", "75%", "50%", "25%", "5%")
# 
# ## colors for degrees (Bachelors, Massters, Doctorate in reverse order)
# cols_degree <- c("#e64500", "#FFCC00", darken(bl_col, .1))
# 
# ## gradient colors for position
# colfunc <- colorRampPalette(c(bl_col, "#bce2d5"))
# pos_cols <- colfunc(10)
```


```{r} 

# DATA LOADING

samples <- rio::import(here::here("proc_data", "samples_50cities.rds")) %>%
  mutate(
    geodist_miles = round(geodist * 0.62137119224, 4), # the distance in American miles instead of km
    drop = -drop, # we want the drop to be negative
    # convert the city to factor and order by population:
    City = fct_relevel(City, 
                       levels = c(
                         "New-York",
                         "Los-Angeles",
                         "Chicago",
                         "Miami",
                         "Dallas",
                         "Philadelphia",
                         "Houston",
                         "Atlanta",
                         "Washington",
                         "Boston",
                         "Phoenix",
                         "Seattle",
                         "San-Francisco",
                         "Detroit",
                         "San-Diego",
                         "Minneapolis",
                         "Tampa",
                         "Denver",
                         "Brooklyn",
                         "Queens",
                         "Riverside",
                         "Baltimore",
                         "Las-Vegas",
                         "Portland",
                         "San-Antonio",
                         "St.-Louis",
                         "Sacramento",
                         "Orlando",
                         "San-Jose",
                         "Cleveland",
                         "Pittsburgh",
                         "Austin",
                         "Cincinnati",
                         "Kansas-City",
                         "Indianapolis",
                         "Columbus",
                         "Charlotte",
                         "Virginia-Beach",
                         "Bronx",
                         "Milwaukee",
                         "Providence",
                         "Jacksonville",
                         "Salt-Lake-City",
                         "Nashville",
                         "Richmond",
                         "Memphis",
                         "Raleigh",
                         "New-Orleans",
                         "Louisville",
                         "Oklahoma-City"
                       ))
  )

# # check how many samples in first mile:
# ten_miles_samples = c("11", "12", "13", "14", "15","16", "17", "18","19", "20")
# samples %>% filter(Sample %in% ten_miles_samples) %>% count(geodist_miles) %>% mutate(
#   rough_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1), labels = FALSE), # bin by mile
#   rough_geodist = ifelse(is.na(rough_geodist), 0, rough_geodist) # the bin 0 is 0 instead of NA
# ) %>%
#   ungroup() %>%
#   group_by(rough_geodist) %>%
#   summarise(sum_n = sum(n)) %>%
#   View()
# 
# samples  %>% filter(Sample %in% ten_miles_samples) %>% filter(geodist_miles < 1, geodist_miles != 0) %>% count(Sample)

```


```{r}

# DATA PROCESSING
#   we need an easy way to plot the distance to origin for the plots.
#   so, we bin the distance by mile, an compute the average rank in a bin.
# we create 2 tibbles, one with an average by city
# and another with an average by city and sample.

# method: because the geo distance varies, and is not the EXACT same
# btw cities and samples, we bin by mile to plot.

# we start by adding "bin" (rounding) the geographical distance:
samples <- samples %>% 
  mutate(
    rough_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1), labels = FALSE), # bin by mile 
    rough_geodist = ifelse(is.na(rough_geodist), 0, rough_geodist), # the bin 0 is 0 instead of NA
    granular_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1, 0.1), labels = FALSE)/10, # bin by 10th of a mile 
    granular_geodist = ifelse(is.na(granular_geodist), 0, granular_geodist), # the bin 0 is 0 instead of NA
    rank = ifelse(rank == 21, 25, rank) # we use 25 to code missing values, instead of 21 -> better visibility, better highlight of difference.
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()


# a tibble with an average by city
avg_by_city <- samples %>%
  group_by(City, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            n_samples = n(),
            sd = sd(drop),
            avg_rank = mean(rank),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  )

# a tibble with an average by city and sample
avg_by_city_and_firm <- samples %>%
  group_by(City, Sample, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            avg_rank = mean(rank),
            n_samples = n(),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()


# a tibble with an average by sample, regardless of city
avg_by_firm <- samples %>%
  group_by(unique_sample, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            n_samples = n(),
            sd = sd(drop),
            avg_rank = mean(rank),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  )


# a tibble with a granularity of tenth of a mile:
# a tibble with an average by city and sample
avg_by_city_and_firm_granular <- samples %>%
  group_by(City, Sample, unique_sample, granular_geodist) %>%
  summarise(avg_drop = mean(drop),
            avg_rank = mean(rank),
            n_samples = n(),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()

```

# Introduction

Google relies on user proximity to provide local results for keywords. How strong is the proximity factor? How fast does the ranking decrease by distance from the location of a business?  

The goals of the study are to try to estimate the drop in the ranking by geographical distance and to measure the variability due to the local context (city).

## Methods

For this study, we focused on personal injury lawyers in major US cities. We collected 20 top-ranking personal injury lawyers in each of the 50 largest cities. 

For each of these law firms, we used the service [Local Falcon](https://www.localfalcon.com/) to collect Google My Business rankings for listings that show up either in the Maps portion of the organic search or from a search in the Google Maps Local Finder (i.e. Google Maps).

We collected their rankings for the keyword _car accident lawyer_ at 225 locations on a 15x15 grid centered on their geographic location.  

This is an example for the city of Miami:  
![example_miami_1](../doc/example_scan_miami_1.png){#id .class width=80% height=80%}   

At the location of the law firm, it ranks 1st for the keyword _car accident lawyer_. Its ranking drops, however, as soon we are further away from its location. At the fringe of the grid, the law firm does not appear anymore in the top 20 (its exact ranking is not tracked anymore by Local Falcon).   

This drop in the ranking can vary drastically between law firms, even in the same city. We see this variation if we flank our initial example with 2 other samples from Miami:    
![example_miami_2](../doc/example_scan_miami_2.png){#id .class width=32% height=32%} ![example_miami_1](../doc/example_scan_miami_1.png){#id .class width=32% height=32%} ![example_miami_3](../doc/example_scan_miami_3.png){#id .class width=32% height=32%}    
On the left, we see a very quick drop in the ranking. On the right, we see the case of a law firm which ranking does not drop much. The grid is always centered on the location of the target law firm.     

To account for this high variation between the firm, we need to collect several samples in each city; we collected 20. We used a radius of 10 miles. This allows us to both highlight the drop in ranking around the exact location of the firm and identify the distance where most of the firms drop out of the top 20. 
Furthermore, for the 10 largest cities, we also collected 10 samples at a 5 miles radius, a finer granularity, to better highlight the drop in ranking around the firm.   

&nbsp;

Most of the 1100 law firms rank 1st at their own location (56%).  

```{r, fig.align='center', fig.height=5, out.width='80%'}

avg_by_city_and_firm %>% 
  filter(rough_geodist == 0) %>%
  count(avg_rank) %>%
  mutate(initial_rank_in_perc = n/sum(n),
         seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  ggplot(aes(x = avg_rank, y = initial_rank_in_perc, fill = seg_color)) +
  geom_col() +
  scale_fill_identity() +
  scale_y_continuous(labels = scales::percent) +
  xlab("Rank at own location") +
  ylab("Percentage of law firms")

```

&nbsp;

From the latitude and longitude of each of the 225 measurements on the 15x15 grid, we compute the geographical distance to the location of the target law firm. We then average the ranking of a law firm by mile distance to its own location.  

**There is a major caveat of the data collected with Local Falcon: Local Falcon does not collect rankings above 20** - the first page of search results; they are just collected as "20+". So, in order to numerically estimate the decline in ranking, for instance by computing the average rank at a certain distance from a law firm's localization, we need to impute the value of these missing ranks. For the sake of this study, **we assigned the value of 25 for all "20+" measurements**. This is not perfect and has an impact on the computation of the average ranking. Nevertheless, it still allows us to visualize this decline.   

For instance, with our previous example in Miami, we see that the law firm ranked first at its own location (distance = 0 miles). The ranking drops quickly, and the average position of all the measurements taken between 0 and 1 miles average to ~9. The average rank oscillates then around 20 as from the third mile already. The further away from the location, the more often the firm's ranking is high or out of the top 20, as we used the value of 25 to for "+20", this is reflected in the average. We highlighted the average in orange when it was above 20. The law firms ranks mostly out of the top 20 there.    

```{r, fig.align='center', fig.height=5, out.width='80%'}

avg_by_city_and_firm %>% 
  filter(City == "Miami",
         Sample == "12") %>%
  ggplot(mapping = aes(x = rough_geodist, y = avg_rank, color = seg_color, group = 1)) +
  geom_point(size = 2) +
  geom_line(color = "black", linetype = "dashed") + 
  scale_color_identity() + 
  scale_y_reverse(
    breaks = c(1,5,10,15,20,25)
  ) +
  # scale_y_reverse() +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 1), 
    minor_breaks = NULL) + 
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)") +
  annotate(geom = "text", x=4, y=1, 
           label="This firm ranks 1st at its location (0 miles)...") +
  annotate(geom = "text", x=5.5, y=9, 
           label="... and quickly ranks, on average, 9th after 1 mile.")

```


To obtain more stable measurements of the drop in ranking, we average the rankings from each law firm. This is the reason why we collected 20 samples per city. 


# Observations

## Rank at Each Mile from Location

We start by visualizing the rank at each mile from the center location for each law firm in each city. Each line is a sample - a law firm.   

First, for the most populated and less populated city:  

```{r, fig.align='center', fig.height=4.7, out.width='100%'}

two_cities <- avg_by_city_and_firm %>% 
  filter(City %in% c("New-York", "Oklahoma-City")) %>%
  # mutate(avg_rank = ifelse(avg_rank > 20, 25, avg_rank)) %>%
  # mutate(seg_color = ifelse(avg_rank > 20, "orange", "black")) %>% # to color the +20 samples
  droplevels()

rank_all_samples_2cities <- ggplot(data = two_cities, 
                                   mapping = aes(x = rough_geodist, 
                                                 y = avg_rank, 
                                                 group = Sample,
                                                 color = seg_color)
                                   # color = factor(seg_color)
) +
  geom_line(alpha = 0.4) +
  geom_point(alpha = 0.4) +
  # scale_color_manual(values = two_cities$seg_color) +
  scale_color_identity() +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Ranking Does Not Drop Equally for All Firms",
    subtitle = "Some firms drop quickly out of the top 20, other don't.\nEach grey line is a sample (a law firm).\nA rank above 20 means '+20' and is shown in orange."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)")

if(save == T){ 
  plot_to_save <- rank_all_samples_2cities +
    facet_wrap(vars(City), ncol = 2)
  
  ggsave(here::here("plots",
                    "rank_all_samples_2cities-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples_2cities +
  facet_wrap(vars(City), ncol = 1) + 
  my_theme()

```


Then, for all 50 largest US cities:  

```{r, fig.align='center', fig.height=10, out.width='100%'}

rank_all_samples <- ggplot(data = avg_by_city_and_firm, 
                           mapping = aes(x = rough_geodist, 
                                         y = avg_rank, 
                                         group = Sample,
                                         color = seg_color)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_color_identity() +
  scale_y_reverse() +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL)
# labs(
#   title = "The Ranking Drops by Distance",
#   subtitle = "However, the magnitude of the drop varies greatly between law firms: the highest ranking firms drop much less. \nEach grey line is a sample (a law firm).A rank of 21  means '+20': out of the top 20."
# ) +
# xlab("Distance in miles to the location of the law firm") +
# ylab("Ranking (average, binned by mile)")

if(save == T){ 
  plot_to_save <- rank_all_samples +
    facet_wrap(vars(City), ncol = 5)
  
  ggsave(here::here("plots",
                    "rank_all_samples-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() + 
  theme_void()

```

We observe that the patterns are slightly different between cities. There is nevertheless a consistency: the drop in ranking varies greatly between law firms. Some law firms do only see a small drop in their ranking, even at 5 or 10 miles from their location. Other law firm quickly drop out of the top 20 (showed in orange on the plot).    

&nbsp;

Because there is a high variability between the law firms, it is useful to show the __<span style="color:#D21D5C">average rank at each mile</span>__ to highlight the general trend:  

```{r, fig.align='center', fig.height=4.7, out.width='100%'}

rank_all_samples_2cities_avg <- ggplot(data = two_cities, 
                                       mapping = aes(x = rough_geodist, 
                                                     y = avg_rank, 
                                                     group = Sample,
                                                     color = seg_color)) +
  geom_line(alpha = 0.4) +
  scale_color_identity() + 
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = (avg_by_city %>% 
                      filter(City %in% c("New-York", "Oklahoma-City"))), 
            mapping = aes(x = rough_geodist, 
                          y = avg_rank, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Ranking Drops by Distance",
    subtitle = "The magnitude of the drop varies greatly between law firms: the highest ranking firms drop much less. \nEach grey line is a sample (a law firm), and their average is in pink. \nA rank of 25  means '+20': out of the top 20 and is shown in orange."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)")

if(save == T){ 
  plot_to_save <- rank_all_samples_2cities_avg +
    facet_wrap(vars(City), ncol = 2)
  
  ggsave(here::here("plots",
                    "rank_all_samples_2cities_avg-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples_2cities_avg +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme()

```


And for all 50 cities:  

```{r, fig.align='center', fig.height=10, out.width='100%'}

rank_all_samples_avg <- ggplot(data = avg_by_city_and_firm, 
                               mapping = aes(x = rough_geodist, 
                                             y = avg_rank, 
                                             group = Sample,
                                             color = seg_color)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = avg_by_city, 
            mapping = aes(x = rough_geodist, 
                          y = avg_rank, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_y_reverse() +
  scale_color_identity() +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL)

if(save == T){ 
  plot_to_save <- rank_all_samples_avg +
    facet_wrap(vars(City), ncol = 5)
  
  ggsave(here::here("plots",
                    "rank_all_samples_avg-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples_avg +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() + 
  theme_void()

```


The average rank across all law firms is shown in pink. We see that the shape of the average rank by mile is similar between cities: it drops fast in the first mile, and then slowly stabilizes.   

It is computed with a rank of 25 for the firms out of the top 20 and for which the rank is not recorded anymore by Local Falcon. This is distorting the "true" average, which is unknown and likely lower at large miles. Another probable distortion is that the ranking is likely to "continuously" decline, and not stabilize at a certain value. The current impression of a stabilization of the mean is due to the constant value of 25 attributed to the "+20" measurements. Nevertheless, our method allows for a visualization of an estimate of the average drop in each cities. This estimate is just more precise for smaller distances.     



### Drop from Initial Position (Relative Ranking)

In order to better compare the drop in ranking between law firms and cities, we can visualize their drop from their initial position - the relative ranking. Note that this drop is still computed with a value of 25 for the "+20" measurements.   

First, for the most populated and less populated city:  


```{r fig.align='center', fig.height=4.5, out.width='100%'}

average_drop_2cities <- ggplot(data = two_cities, 
                               mapping = aes(
                                 x = rough_geodist, 
                                 y = avg_drop, 
                                 group = Sample)) +
  geom_line(alpha = 0.4) +
  geom_line(data = (avg_by_city %>% 
                      filter(City %in% c("New-York", "Oklahoma-City"))), 
            mapping = aes(x = rough_geodist, y = avg_drop, group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Drop in Ranking for Each Law Firm",
    subtitle = "Each grey line is a sample (a law firm), and their average is in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")


if(save == T){ 
  plot_to_save <- average_drop_2cities +
    facet_wrap(vars(City), ncol = 2) 
  
  ggsave(
    here::here("plots",
               "average_drop_2cities-50cities.pdf"),
    plot_to_save, 
    width = 15, height = 40, device = cairo_pdf)
}

average_drop_2cities +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme()

```


Then, for all 50 cities:  


```{r fig.align='center', fig.height=10, out.width='100%'}

average_drop_all_samples <- ggplot(data = avg_by_city_and_firm, 
                                   mapping = aes(x = rough_geodist, 
                                                 y = avg_drop, 
                                                 group = Sample)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = avg_by_city, 
            mapping = aes(x = rough_geodist, 
                          y = avg_drop, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL)

if(save == T){ 
  plot_to_save <- average_drop_all_samples +
    facet_wrap(vars(City), ncol = 5) 
  
  ggsave(
    here::here("plots",
               "average_drop_all_samples-50cities.pdf"),
    plot_to_save, 
    width = 15, height = 40, device = cairo_pdf)
}

average_drop_all_samples +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() +
  theme_void()


```

The drop is always 0 at the location of the firms. We observe that the shape of the drop, despite slight variations, is similar between cities.  

We can superimpose all the drops in one single plot to show **the average drop in ranking in relation to the distance from the location of a firm for each city**:  


```{r fig.align='center', fig.height=4.5, out.width='100%'}

data_ends <- avg_by_city %>%
  group_by(City) %>%
  mutate(last_geodist = max(rough_geodist)) %>%
  ungroup() %>%
  filter(rough_geodist == last_geodist)


avg_drop_for_all_cities <- ggplot(data = avg_by_city, 
                                  mapping = aes(x = rough_geodist, 
                                                y = avg_drop,
                                                group = City)) +
  geom_line(alpha = 1, color = r_col) +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Average Drop by Mile in each City"
    # subtitle = "Each grey line is a sample (a law firm), and their average is in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)") +
  geom_text_repel(
    aes(x = rough_geodist, y = avg_drop,  label = City), data = data_ends,
    fontface ="plain", 
    color = "black", 
    size = 3,
    # direction = "y"
  )

avg_drop_for_all_cities

if(save == T){ 
  ggsave(
    here::here("plots",
               "avg_drop_for_all_cities-50cities.pdf"),
    plot_to_save, 
    width = 15, height = 15, device = cairo_pdf)
}


```

Note that, again, the average is computed with a constant value of "25" for the samples out of the top 20. This explains the stabilization of the curve at large distances. Nevertheless, all cities see a drop of -5 to -12 in the average ranking of the law firms in the first mile. The drop seems to be larger in the Queens than in New-Orleans.    


```{r include=FALSE}

#  average of the drop between all samples in all cities in a table:  

avg_by_city_and_firm %>% 
  group_by(rough_geodist) %>%
  summarise(average_drop = mean(avg_drop)) %>%
  select(`Distance to Firm (miles)` = rough_geodist, 
         `Average Cumulative Drop (position)` = average_drop) %>%
  kable(
    format = "html",
    digits = 1
  ) %>% 
  kable_styling(
    bootstrap_options = 'condensed',
    full_width = FALSE,
    position = 'center'
  )

```



### Exponential Decay?

As we just saw, the drop in term of ranking has a similar shape in all cities. The drop seems to follow more or less a rule of [exponential decay](https://en.wikipedia.org/wiki/Exponential_decay): it decreases at a rate proportional to its current value. At first it decreases fast and then reach stability.  

The _exponential decay function_ can be formalized like this: $Drop(d) = Drop0 * e^{-λd})$, where $Drop(d)$ is the drop at a distance $d$ and $λ$ is the decay constant.

If we fit an _exponential decay function_ to the average, we estimate $λ$. If we have an estimate of $λ$, we can use the _exponential decay function_ to estimate the drop which would be expected, on average, at a certain distance $d$.  

We start by illustrating the decay with all the samples taken in all cities, together. In order to get a better estimate of the exponential decay function, we average the data each tenth of a mile. In pink, we see the average drop in ranking regardless of the city:  

````{r fig.align='center', fig.height=6, out.width='100%'}

avg_drop_total <- avg_by_city_and_firm_granular %>%
  group_by(granular_geodist) %>%
  summarise(avg_drop = mean(avg_drop))

avg_drop_total_no_zero <- avg_drop_total %>%
  mutate(granular_geodist = ifelse(granular_geodist == 0, 0.001, granular_geodist))

avg_drop_overall <- ggplot(data = avg_by_city_and_firm_granular, 
                           mapping = aes(x = granular_geodist, 
                                         y = avg_drop,
                                         group = unique_sample)) +
  geom_line(alpha = 0.1) +
  geom_line(data = avg_drop_total, 
            mapping = aes(x = granular_geodist, 
                          y = avg_drop, 
                          group = 1), 
            size = 1, 
            color = r_col,
            linetype = "dashed") +
  geom_point(data = avg_drop_total, 
             mapping = aes(x = granular_geodist, 
                           y = avg_drop, 
                           group = 1), 
             size = 2, 
             color = r_col) +
  # geom_smooth(
  #   data = avg_drop_total_no_zero,
  #   mapping = aes(x = granular_geodist, 
  #                 y = avg_drop,
  #                 group = 1),
  #   
  #   method="glm", 
  #   formula = y ~ I(log(x)),
  #   se=FALSE, size=1, color = "#13D18F") +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm_granular$granular_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Drop by Mile",
    subtitle = "Each grey line is a sample (a law firm), all cities included.\nMeasurement are binned each tenth of a mile.\nThe average is shown in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")

avg_drop_overall

# if(save == T){ 
#   ggsave(
#     here::here("plots",
#                "avg_drop_overall-50cities.pdf"),
#     plot_to_save, 
#     width = 15, height = 15, device = cairo_pdf)
# }


```

Then we can fit an _exponential decay function_ to the average:  


```{r}

# start here from avg_drop_total, 0 is OK, fit 

avg_drop_overall <- ggplot(data = avg_by_city_and_firm_granular, 
                           mapping = aes(x = granular_geodist, 
                                         y = avg_drop,
                                         group = unique_sample)) +
  geom_line(alpha = 0.1) +
  geom_line(data = avg_drop_total, 
            mapping = aes(x = granular_geodist, 
                          y = avg_drop, 
                          group = 1), 
            size = 1, 
            color = r_col,
            linetype = "dashed") +
  geom_point(data = avg_drop_total, 
             mapping = aes(x = granular_geodist, 
                           y = avg_drop, 
                           group = 1), 
             size = 2, 
             color = r_col) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm_granular$granular_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Drop by Mile",
    subtitle = "Each grey line is a sample (a law firm), all cities included.\nMeasurement are binned each tenth of a mile.\nThe average is shown in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")

avg_drop_overall


```



```{r}
# Experimenting with fitting the decay:

# normalize btw 20 and 0:
data_for_fit <- avg_drop_total_no_zero %>%
  mutate(
    avg_drop_norm = 0 + (((avg_drop - min(avg_drop)) * (20 - 0))  / (max(avg_drop) - min(avg_drop))),
    avg_drop_translatd = avg_drop + 20
  ) 

data_for_fit <- avg_drop_total %>%
  mutate(
    avg_drop_norm =avg_drop,
    avg_drop_translatd = avg_drop
  )

# linearizing:
fit1 = lm(avg_drop_translatd ~ granular_geodist, data = data_for_fit)
summary(fit1)

# exp decay
y0 = min(data_for_fit$avg_drop_translatd)
yf = max(data_for_fit$avg_drop_translatd)
fit2 <- nls(avg_drop_translatd ~ yf + (y0 - yf) * exp(-alpha * granular_geodist), 
            data = data_for_fit,
            start = list(y0 = y0, yf = yf, alpha = 5),
)
summary(fit2)

# asymptotic regression function (a self-starting function):
fit3 <- nls(avg_drop_translatd ~ SSasymp(granular_geodist, yf, y0, log_alpha), data = data_for_fit)
summary(fit3)



tmp <- data_for_fit %>%
  mutate(
    pred1 = predict(fit1),
    pred2 = predict(fit2),
    pred3 = predict(fit3)
  )

ggplot(tmp, aes(x=granular_geodist, y = avg_drop_translatd)) +
  geom_line(color = r_col) +
  geom_line(aes(x=granular_geodist, y = pred1), color = "red") +
  geom_line(aes(x=granular_geodist, y = pred2), color = "blue", linetype = "dashed", size=3) +
  geom_line(aes(x=granular_geodist, y = pred3), color = "orange", linetype = "dashed") +
  stat_smooth(method = "nls", formula = y ~ SSasymp(x, Asym, R0, lrc), se = FALSE, color = "black", linetype = "dashed") +
  geom_smooth( 
    method="glm", 
    formula = y ~ I(log(x)),
    se=FALSE, size=1, color = "#13D18F", linetype = "dashed") +
  theme_minimal()


```



&nbsp;  

&nbsp;  

**[HERE IS WHERE I AM]**   

&nbsp;   

&nbsp;  

==>  ADD HERE THE EXPONENTIAL DECAY FIT --

&nbsp;


## When are Law Firms Dropping Out of the Top 20?

Google Maps shows 20 results on the first search page and Local Falcon does not collect the ranking above the top 20. We saw above that the ranking was dropping fast in the first mile, but also that not all the firms were dropping out of the top 20 after 10 miles. And this, in all cities, regardless of their area.  

For example, a 10-mile radius is enough to completely cover the city of Boston and its surroundings, but this is absolutely not the case in Los Angeles. However, in both cases, we identify companies that fall out of the top 20 after 5 or 10 miles and others that do not fall out of the top 20.  

How does the proportion of law firms out of the top 20 change with distance?  

We first have a look at New-York and Oklahoma-City:  

```{r fig.align='center', fig.height=4.5, out.width='100%'}

two_cities_no_firms <- avg_by_city %>% 
  filter(City %in% c("New-York", "Oklahoma-City")) %>%
  # mutate(avg_rank = ifelse(avg_rank == 21, NA, avg_rank)) %>%
  droplevels()

perc_out_of_top20_two_cities <- ggplot(data = two_cities_no_firms, 
                                       mapping = aes(x = rough_geodist, 
                                                     y = percentage_out_of_top20, 
                                                     group = 1)) +
  geom_point(size = 0.4) +
  geom_line() +
  geom_area(alpha = 0.3, fill = r_col) + 
  facet_wrap(vars(City), ncol = 5) + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city$rough_geodist), by = 2), 
    minor_breaks = NULL 
  ) + 
  coord_cartesian(clip = "off") +
  labs(
    title = "Percentage of the Firms Out of the Top 20, by Mile",
    subtitle = "In New York, 80% of the law firms rank out of the top 20 after 10 miles.\nThis is far to be the case in Oklahoma City."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Percentage of the firms\nout of the top 20") + 
  geom_text_repel(
    aes(x = rough_geodist, 
        y = percentage_out_of_top20,  
        label = paste0(as.character(round(100*percentage_out_of_top20,0)),"%")
    ), 
    data = data_ends %>% filter(City %in% c("New-York", "Oklahoma-City")),
    fontface ="plain", 
    color = "black", 
    size = 3,
    # nudge_y = 0.01,
    min.segment.length = 5,
    direction = "y",
    xlim = c(14.2,18)
  )

# average_drop

if(save == T){ 
  plot_to_save <- perc_out_of_top20_two_cities +
    facet_wrap(vars(City), ncol = 2) +
    ylab("Percentage of the firms\nout of the top 20")
  
  ggsave(here::here("plots",
                    "perc_out_of_top20_two_cities-50cities.pdf"),
         perc_out_of_top20_two_cities, 
         width = 15, 
         height = 8, 
         device = cairo_pdf)
}

perc_out_of_top20_two_cities +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme() 


```

There is a radical difference here. The percentage of law firms which dropped out of the top 20 rises to 80% in New York, after around 10 miles. Whereas in Oklahoma city, this number never rises above 30%; a larger proportion of law firms rank well, even at large distances.   

Then, for all the 50 largest U.S. cities:  

```{r fig.align='center', fig.height=12, out.width='100%'}

perc_out_of_top20 <- ggplot(data = avg_by_city, 
                            mapping = aes(x = rough_geodist, 
                                          y = percentage_out_of_top20, 
                                          group = 1)) +
  # geom_point(size = 0.2) +
  geom_line() +
  geom_area(alpha = 0.3, fill = r_col) + 
  facet_wrap(vars(City), ncol = 5) + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city$rough_geodist), by = 5), 
    minor_breaks = NULL 
  ) + 
  coord_cartesian(xlim = c(0, 16), clip = "off") + # for the labels to the right
  labs(
    title = "Percentage of the Firms Out of the Top 20, by Mile") +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Percentage of the firms out of the top 20") + 
  geom_text_repel(
    aes(x = rough_geodist, 
        y = percentage_out_of_top20,  
        label = paste0(as.character(round(100*percentage_out_of_top20,0)),"%")
    ), 
    data = data_ends,
    fontface ="bold", 
    color = "black", 
    size = 2.5,
    direction = "y",
    min.segment.length = 2,
    xlim = c(15,20)
  )

# average_drop

# if(save == T){ 
#   plot_to_save <- perc_out_of_top20 +
#     facet_wrap(vars(City), ncol = 5) +
#     ylab("Percentage of the firms\nout of the top 20")
#   
#   ggsave(here::here("plots",
#                     "perc_out_of_top20-50cities.pdf"),
#          perc_out_of_top20, 
#          width = 15, 
#          height = 8, 
#          device = cairo_pdf)
# }

perc_out_of_top20 +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() +
  theme(
    strip.text = element_text(size = 7.8,
                              color = "black",
                              face = "bold"),
    axis.line.x = element_line(color = "black",
                               size = .2),
    axis.line.y = element_line(color = "black",
                               size = .2),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 7,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
  )


```

The percentage of law firms which dropped out of the top 20 at the largest distance ranges from 27% in Pittsburgh to 92% in the Queens. 

The cities are ordered by population size. It seems that the percentage of law firms which are able to remain in the top 20 is lower in largest cities.  

__This measure is likely an estimate of the competition in each city.__  

Note that these percentages are computed on 20 sample law firms. Please note also that the largest distance is not exactly the same in all cities. This differences are due to the precision of Local Falcon, geolocalization, and computation of geographical distance from coordinates.  






# Summary and Key Observations

As this analysis included a certain amount of uncertainty, in particular with regards to the variability of the results between each city and between each firm, we preferred to proceed in stages and offer Rankings.io preliminary analyses with the 10 largest cities.     

We sampled 20 personal injury law firms in the 10 largest cities (10 with a radius of 5 miles, and 10 with a radius of 10 miles). For each, we measured their ranking for the keyword "car accident lawyer" at 225 locations disposed on a squared grid of 5/10 miles "radius" around the original location of the firm, using Local Falcon. We then compute the rankings and relative ranking (drop) of each law firm for each mile away from its location.  

## Key Observations 

1. The ranking drops dramatically in the first mile; in all cities. On average, the drop in ranking in the first mile is -7.4 positions.   

2. The drop in ranking varies greatly between law firms. Some top-ranking firms do not even see a drop in the 10-mile radius. This means that there is probably no distance that would guarantee that all of the law firms in a given city drop out of the top 20.       

3. After the quick drop, the average ranking stabilizes or decreases much slower. This effect is partly due to observation 2: we compute an average between law firms still ranking well and law firms which ranking is imputed to 21 because they are out of the top 20. This effect, albeit with some slight variations, is seen in all cities.     

4. The percentage of law firms that dropped out of the top 20 for each mile distance is varying between cities. For instance, it jumps to almost 40% in the first mile in Atlanta or Philadelphia, but never increases much more. On the contrary, it reaches almost 80% in Boston or Washington DC.     

All these observations might have an impact on the current Rankings.io offer of a 5-mile geographic radius around a client’s headquarters to take more than one client in larger cities.   



