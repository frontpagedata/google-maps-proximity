---
title: "Google Maps Ranking - Proximity Study"
author: "François Delavy and FrontPage Data for Rankings.io"
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    theme: paper
    highlight: kate
    # code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    keep_md: true # keep the intermediary files, including the plots as .png
editor_options: 
  chunk_output_type: console
---


<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
background-color: #D21D5C;
border-color: #D21D5C;
}

body {
font-family: FiraSans-Regular;
color: #444444;
font-size: 14px;
}

h1 {
font-weight: bold;
font-size: 28px;
}

h1.title {
font-size: 30px;
color: #D21D5C;
}

h2 {
font-size: 24px;
}

h3 {
font-size: 18px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.showtext = TRUE, dpi = 700,
                      echo = FALSE # hide code for now
)

knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",", small.mark = ",", scientific = F)
})

Sys.setlocale("LC_TIME", "C")
# extrafont::loadfonts(device = "win")
extrafont::loadfonts()

```


```{r prep}
# SETUP

## packages: remove or add your necessary packages

# required_packages <- c("tidyverse", "readxl", "ggthemes", "hrbrthemes", "extrafont", "plotly", "scales", "stringr", "gganimate", "here", "tidytext", "sentimentr", "scales", "DT", "here", "sm", "mblm", "glue", "fs", "knitr", "rmdformats", "janitor", "urltools", "colorspace", "pdftools", "showtext")

required_packages <- c("tidyverse", "extrafont", "here", "colorspace", "pdftools", "kableExtra", "ggrepel")

for(i in required_packages) { 
  if(!require(i, character.only = T)) {
    
    #  if package is not existing, install then load the package
    install.packages(i, dependencies = T)
    require(i, character.only = T)
  }
}


## save plots?
# save <- TRUE
save <- FALSE

## quality of png's
dpi <- 750

## font adjust; please adjust to client´s website
#extrafont::loadfonts(device = "win", quiet = TRUE)
#font_add_google("Montserrat", "Montserrat")
# font_add_google("Overpass", "Overpass")
# font_add_google("Overpass Mono", "Overpass Mono")



## theme updates; please adjust to client´s website
#theme_set(ggthemes::theme_clean(base_size = 15))
theme_set(ggthemes::theme_clean(base_size = 12, base_family = "FiraSans-Regular"))


theme_update(plot.margin = margin(30, 30, 30, 30),
             plot.background = element_rect(color = "white",
                                            fill = "white"),
             plot.title = element_text(size = 20,
                                       face = "bold",
                                       lineheight = 1.05,
                                       hjust = .5,
                                       margin = margin(10, 0, 25, 0)),
             plot.title.position = "plot",
             plot.subtitle = element_text(size = 16),
             plot.caption = element_text(color = "grey40",
                                         size = 9,
                                         margin = margin(20, 0, -20, 0)),
             plot.caption.position = "plot",
             axis.line.x = element_line(color = "black",
                                        size = .8),
             axis.line.y = element_line(color = "black",
                                        size = .8),
             axis.title.x = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(t = 20)),
             axis.title.y = element_text(size = 16,
                                         face = "bold",
                                         margin = margin(r = 20)),
             axis.text = element_text(size = 11,
                                      color = "black",
                                      face = "bold"),
             axis.text.x = element_text(margin = margin(t = 10)),
             axis.text.y = element_text(margin = margin(r = 10)),
             axis.ticks = element_blank(),
             panel.grid.major.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.major.y = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.x = element_line(size = .6,
                                               color = "#eaeaea",
                                               linetype = "solid"),
             panel.grid.minor.y = element_blank(),
             panel.spacing.x = unit(4, "lines"),
             panel.spacing.y = unit(2, "lines"),
             legend.position = "top",
             legend.title = element_text(family = "Montserrat",
                                         color = "black",
                                         size = 14,
                                         margin = margin(5, 0, 5, 0)),
             legend.text = element_text(family = "Montserrat",
                                        color = "black",
                                        size = 11,
                                        margin = margin(4.5, 4.5, 4.5, 4.5)),
             legend.background = element_rect(fill = NA,
                                              color = NA),
             legend.key = element_rect(color = NA, fill = NA),
             #legend.key.width = unit(5, "lines"),
             #legend.spacing.x = unit(.05, "pt"),
             #legend.spacing.y = unit(.55, "pt"),
             #legend.margin = margin(0, 0, 10, 0),
             strip.text = element_text(face = "bold",
                                       margin = margin(b = 10)))

my_theme <- function(){
  theme(
    # plot.margin = margin(30, 30, 30, 30),
    plot.background = element_rect(color = "white",
                                   fill = "white"),
    plot.title = element_text(size = 14),
    plot.title.position = "plot",
    plot.subtitle = element_text(size = 10),
    plot.caption = element_text(color = "grey40",
                                size = 9),
    plot.caption.position = "plot",
    axis.line.x = element_line(color = "black",
                               size = .8),
    axis.line.y = element_line(color = "black",
                               size = .8),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 9,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_line(size = .6,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.y = element_blank(),
    panel.spacing.x = unit(2, "lines"),
    panel.spacing.y = unit(1, "lines")
  )
}

## theme settings for flipped plots
theme_flip <-
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_line(size = .6,
                                          color = "#eaeaea"))

## theme settings for maps
theme_map <- 
  theme_void(base_family = "Montserrat") +
  theme(legend.direction = "horizontal",
        legend.box = "horizontal",
        legend.margin = margin(10, 10, 10, 10),
        legend.title = element_text(size = 17, 
                                    face = "bold"),
        legend.text = element_text(color = "grey33",
                                   size = 12),
        plot.margin = margin(15, 5, 15, 5),
        plot.title = element_text(face = "bold",
                                  size = 20,
                                  hjust = .5,
                                  margin = margin(30, 0, 10, 0)),
        plot.subtitle = element_text(face = "bold",
                                     color = "grey33",
                                     size = 17,
                                     hjust = .5,
                                     margin = margin(10, 0, -30, 0)),
        plot.caption = element_text(size = 14,
                                    color = "grey33",
                                    hjust = .97,
                                    margin = margin(-30, 0, 0, 0)))

## numeric format for labels
num_format <- scales::format_format(big.mark = ",", small.mark = ",", scientific = F)

## main colors rankings.io
r_col <- "#D21D5C"

# to be updated if/when needed:
# bl_col <- "#00d188"
# bl_dark <- darken(bl_col, .3, space = "HLS")
# 
# ## colors + labels for interval stripes
# int_cols <- c("#bce2d5", "#79d8b6", bl_col, "#009f66", "#006c45", "#003925")
# int_perc <- c("100%", "95%", "75%", "50%", "25%", "5%")
# 
# ## colors for degrees (Bachelors, Massters, Doctorate in reverse order)
# cols_degree <- c("#e64500", "#FFCC00", darken(bl_col, .1))
# 
# ## gradient colors for position
# colfunc <- colorRampPalette(c(bl_col, "#bce2d5"))
# pos_cols <- colfunc(10)
```


```{r} 

# DATA LOADING

samples <- rio::import(here::here("proc_data", "samples_50cities.rds")) %>%
  mutate(
    geodist_miles = round(geodist * 0.62137119224, 4), # the distance in American miles instead of km
    drop = -drop, # we want the drop to be negative
    # convert the city to factor and order by population:
    City = fct_relevel(City, 
                       levels = c(
                         "New-York",
                         "Los-Angeles",
                         "Chicago",
                         "Miami",
                         "Dallas",
                         "Philadelphia",
                         "Houston",
                         "Atlanta",
                         "Washington",
                         "Boston",
                         "Phoenix",
                         "Seattle",
                         "San-Francisco",
                         "Detroit",
                         "San-Diego",
                         "Minneapolis",
                         "Tampa",
                         "Denver",
                         "Brooklyn",
                         "Queens",
                         "Riverside",
                         "Baltimore",
                         "Las-Vegas",
                         "Portland",
                         "San-Antonio",
                         "St.-Louis",
                         "Sacramento",
                         "Orlando",
                         "San-Jose",
                         "Cleveland",
                         "Pittsburgh",
                         "Austin",
                         "Cincinnati",
                         "Kansas-City",
                         "Indianapolis",
                         "Columbus",
                         "Charlotte",
                         "Virginia-Beach",
                         "Bronx",
                         "Milwaukee",
                         "Providence",
                         "Jacksonville",
                         "Salt-Lake-City",
                         "Nashville",
                         "Richmond",
                         "Memphis",
                         "Raleigh",
                         "New-Orleans",
                         "Louisville",
                         "Oklahoma-City"
                       ))
  )

# # check how many samples in first mile:
# ten_miles_samples = c("11", "12", "13", "14", "15","16", "17", "18","19", "20")
# samples %>% filter(Sample %in% ten_miles_samples) %>% count(geodist_miles) %>% mutate(
#   rough_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1), labels = FALSE), # bin by mile
#   rough_geodist = ifelse(is.na(rough_geodist), 0, rough_geodist) # the bin 0 is 0 instead of NA
# ) %>%
#   ungroup() %>%
#   group_by(rough_geodist) %>%
#   summarise(sum_n = sum(n)) %>%
#   View()
# 
# samples  %>% filter(Sample %in% ten_miles_samples) %>% filter(geodist_miles < 1, geodist_miles != 0) %>% count(Sample)

```


```{r}

# DATA PROCESSING
#   we need an easy way to plot the distance to origin for the plots.
#   so, we bin the distance by mile, an compute the average rank in a bin.
# we create 2 tibbles, one with an average by city
# and another with an average by city and sample.

# method: because the geo distance varies, and is not the EXACT same
# btw cities and samples, we bin by mile to plot.

# we start by adding "bin" (rounding) the geographical distance:
samples <- samples %>% 
  mutate(
    rough_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1), labels = FALSE), # bin by mile 
    rough_geodist = ifelse(is.na(rough_geodist), 0, rough_geodist), # the bin 0 is 0 instead of NA
    granular_geodist = cut(geodist_miles, breaks = seq(0, max(samples$geodist_miles)+1, 0.1), labels = FALSE)/10, # bin by 10th of a mile 
    granular_geodist = ifelse(is.na(granular_geodist), 0, granular_geodist), # the bin 0 is 0 instead of NA
    rank = ifelse(rank == 21, 25, rank) # we use 25 to code missing values, instead of 21 -> better visibility, better highlight of difference.
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()


# a tibble with an average by city
avg_by_city <- samples %>%
  group_by(City, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            n_samples = n(),
            sd = sd(drop),
            avg_rank = mean(rank),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  )

# a table to store the values of the last geodist -> used to put label at the end of lines
data_ends <- avg_by_city %>%
  group_by(City) %>%
  mutate(last_geodist = max(rough_geodist)) %>%
  ungroup() %>%
  filter(rough_geodist == last_geodist)


# a tibble with an average by city and sample
avg_by_city_and_firm <- samples %>%
  group_by(City, Sample, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            avg_rank = mean(rank),
            n_samples = n(),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()


# a tibble with an average by sample, regardless of city
avg_by_firm <- samples %>%
  group_by(unique_sample, rough_geodist) %>%
  summarise(avg_drop = mean(drop),
            n_samples = n(),
            sd = sd(drop),
            avg_rank = mean(rank),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  )


# a tibble with a granularity of tenth of a mile:
# a tibble with an average by city and sample
avg_by_city_and_firm_granular <- samples %>%
  group_by(City, Sample, unique_sample, granular_geodist) %>%
  summarise(avg_drop = mean(drop),
            avg_rank = mean(rank),
            n_samples = n(),
            n_samples_out_of_top20 = sum(rank > 20)
  ) %>%
  ungroup() %>%
  mutate(
    percentage_out_of_top20 = (n_samples_out_of_top20 / n_samples),
    # avg_rank = ifelse(avg_rank > 20, 25, avg_rank), # we do not force 25 to +20 averages
    seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  rowwise() %>%
  mutate(
    unique_sample = paste(as.character(City), Sample, collapse = "_") # a unique id
  ) %>%
  ungroup()

```

# Introduction

Google relies on user proximity to provide local results for keywords. How strong is the proximity factor? How fast does the ranking decrease by distance from the location of a business?  

The goals of the study are to try to estimate the drop in the ranking by geographical distance and to measure the variability due to the local context (city).

## Methods

For this study, we focused on personal injury lawyers in major US cities. We collected 20 top-ranking personal injury lawyers in each of the 50 largest cities. 

For each of these law firms, we used the service [Local Falcon](https://www.localfalcon.com/) to collect Google My Business rankings for listings that show up either in the Maps portion of the organic search or from a search in the Google Maps Local Finder (i.e. Google Maps).

We collected their rankings for the keyword _car accident lawyer_ at 225 locations on a 15x15 grid centered on their geographic location.  

This is an example for the city of Miami:  
![example_miami_1](../doc/example_scan_miami_1.png){#id .class width=80% height=80%}   

At the location of the law firm, it ranks 1st for the keyword _car accident lawyer_. Its ranking drops, however, as soon we are further away from its location. At the fringe of the grid, the law firm does not appear anymore in the top 20 (its exact ranking is not tracked anymore by Local Falcon).   

This drop in the ranking can vary drastically between law firms, even in the same city. We see this variation if we flank our initial example with 2 other samples from Miami:    
![example_miami_2](../doc/example_scan_miami_2.png){#id .class width=32% height=32%} ![example_miami_1](../doc/example_scan_miami_1.png){#id .class width=32% height=32%} ![example_miami_3](../doc/example_scan_miami_3.png){#id .class width=32% height=32%}    
On the left, we see a very quick drop in the ranking. On the right, we see the case of a law firm which ranking does not drop much. The grid is always centered on the location of the target law firm.     

To account for this high variation between the firm, we need to collect several samples in each city; we collected 20. We used a radius of 10 miles. This allows us to both highlight the drop in ranking around the exact location of the firm and identify the distance where most of the firms drop out of the top 20. 
Furthermore, for the 10 largest cities, we also collected 10 samples at a 5 miles radius, a finer granularity, to better highlight the drop in ranking around the firm.   

&nbsp;

Most of the 1100 law firms rank 1st at their own location (56%).  

```{r, fig.align='center', fig.height=5, out.width='80%'}

avg_by_city_and_firm %>% 
  filter(rough_geodist == 0) %>%
  count(avg_rank) %>%
  mutate(initial_rank_in_perc = n/sum(n),
         seg_color = ifelse(avg_rank > 20, "orange", "black") # to color the +20 samples
  ) %>%
  ggplot(aes(x = avg_rank, y = initial_rank_in_perc, fill = seg_color)) +
  geom_col() +
  scale_fill_identity() +
  scale_y_continuous(labels = scales::percent, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5)) +
  scale_x_continuous(breaks = c(1,5,10,15,20,25)) +
  labs(
    title = "56% of law firms ranked first at their own location"
  ) +
  xlab("Rank at own location") +
  ylab("Percentage of law firms") 


```

&nbsp;

From the latitude and longitude of each of the 225 measurements on the 15x15 grid, we compute the geographical distance to the location of the target law firm. We then average the ranking of a law firm by mile distance to its own location.  

**There is a major caveat of the data collected with Local Falcon: Local Falcon does not collect rankings above 20** - the first page of search results; they are just collected as "20+". So, in order to numerically estimate the decline in ranking, for instance by computing the average rank at a certain distance from a law firm's localization, we need to impute the value of these missing ranks. For the sake of this study, **we assigned the value of 25 to all "20+" measurements**. This is not perfect and has an impact on the computation of the average ranking. Nevertheless, it still allows us to visualize this decline.   

For instance, with our previous example in Miami, we see that the law firm ranked first at its own location (distance = 0 miles). The ranking drops quickly, and the average position of all the measurements taken between 0 and 1 miles average to ~9. The average rank oscillates then around 20 as from the third mile already. The further away from the location, the more often the firm's ranking is high or out of the top 20, as we used the value of 25 for "+20", this is reflected in the average. The average is in orange when above 20, i.e. where law firms rank mostly out of the top 20.    

```{r, fig.align='center', fig.height=5, out.width='80%'}

avg_by_city_and_firm %>% 
  filter(City == "Miami",
         Sample == "12") %>%
  ggplot(mapping = aes(x = rough_geodist, y = avg_rank, color = seg_color, group = 1)) +
  geom_point(size = 2) +
  geom_line(color = "black", linetype = "dashed") + 
  scale_color_identity() + 
  scale_y_reverse(
    breaks = c(1,5,10,15,20,25)
  ) +
  # scale_y_reverse() +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 1), 
    minor_breaks = NULL) + 
  labs(title = "How to read the visualizations") +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)") +
  annotate(geom = "text", x=4, y=1, 
           label="This firm ranks 1st at its location (0 miles)...") +
  annotate(geom = "text", x=5.5, y=9, 
           label="... and quickly ranks, on average, 9th after 1 mile.")

```


To obtain more stable measurements of the drop in ranking, we average the rankings from each law firm. This is the reason why we collected 20 samples per city. 


# Observations

## Rank at Each Mile from Location

We start by visualizing the rank at each mile from the center location for each law firm in each city. Each line is a sample - a law firm.   

First, for the most populated and less populated city:  

```{r, fig.align='center', fig.height=4.7, out.width='100%'}

two_cities <- avg_by_city_and_firm %>% 
  filter(City %in% c("New-York", "Oklahoma-City")) %>%
  # mutate(avg_rank = ifelse(avg_rank > 20, 25, avg_rank)) %>%
  # mutate(seg_color = ifelse(avg_rank > 20, "orange", "black")) %>% # to color the +20 samples
  droplevels()

rank_all_samples_2cities <- ggplot(data = two_cities, 
                                   mapping = aes(x = rough_geodist, 
                                                 y = avg_rank, 
                                                 group = Sample,
                                                 color = seg_color)
                                   # color = factor(seg_color)
) +
  geom_line(alpha = 0.4) +
  geom_point(alpha = 0.4) +
  # scale_color_manual(values = two_cities$seg_color) +
  scale_color_identity() +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Ranking Does Not Drop Equally for All Firms",
    subtitle = "Some firms drop quickly out of the top 20, other don't.\nEach line is a sample (a law firm).\nA rank above 20 means '+20' and is shown in orange."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)")

if(save == T){ 
  plot_to_save <- rank_all_samples_2cities +
    facet_wrap(vars(City), ncol = 2)
  
  ggsave(here::here("plots",
                    "rank_all_samples_2cities-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples_2cities +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme()

```


Then, for all 50 largest US cities:  

```{r, fig.align='center', fig.height=12, out.width='100%'}

rank_all_samples <- ggplot(data = avg_by_city_and_firm, 
                           mapping = aes(x = rough_geodist, 
                                         y = avg_rank, 
                                         group = Sample,
                                         color = seg_color)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_color_identity() +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) +
  # labs(
  #   title = "The Ranking Drops by Distance",
  #   subtitle = "However, the magnitude of the drop varies greatly between law firms: the highest ranking firms drop much less. \nEach line is a sample (a law firm).A rank of 21  means '+20': out of the top 20."
  # ) +
  xlab("Distance in miles to the location of the law firm")

if(save == T){ 
  plot_to_save <- rank_all_samples +
    facet_wrap(vars(City), ncol = 5)
  
  ggsave(here::here("plots",
                    "rank_all_samples-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() + 
  theme(
    strip.text = element_text(size = 7.8,
                              color = "black",
                              face = "bold"),
    axis.line.x = element_line(color = "black",
                               size = .2),
    axis.line.y = element_line(color = "black",
                               size = .2),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 6,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.spacing.x = unit(0.2, "lines"), # less space around plots
    panel.spacing.y = unit(1, "lines"),
    axis.title.y.left = element_blank() # no axis label (the space is used by the plots instead)
  )

```

We observe that the patterns are slightly different between cities. There is nevertheless a consistency: the drop in ranking varies greatly between law firms. Some law firms do only see a small drop in their ranking, even at 5 or 10 miles from their location. Other law firms quickly drop out of the top 20 (showed in orange on the plot).    

&nbsp;

Because there is a high variability between the law firms, it is useful to show the __<span style="color:#D21D5C">average rank at each mile</span>__ to highlight the general trend:  

```{r, fig.align='center', fig.height=4.7, out.width='100%'}

rank_all_samples_2cities_avg <- ggplot(data = two_cities, 
                                       mapping = aes(x = rough_geodist, 
                                                     y = avg_rank, 
                                                     group = Sample,
                                                     color = seg_color)) +
  geom_line(alpha = 0.4) +
  scale_color_identity() + 
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = (avg_by_city %>% 
                      filter(City %in% c("New-York", "Oklahoma-City"))), 
            mapping = aes(x = rough_geodist, 
                          y = avg_rank, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Ranking Drops by Distance",
    subtitle = "The magnitude of the drop varies greatly between law firms: the highest ranking firms drop much less. \nEach line is a sample (a law firm), and their average is in pink. \nA rank of 25  means '+20' and is shown in orange."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Ranking\n(average, binned by mile)")

if(save == T){ 
  plot_to_save <- rank_all_samples_2cities_avg +
    facet_wrap(vars(City), ncol = 2)
  
  ggsave(here::here("plots",
                    "rank_all_samples_2cities_avg-50cities.pdf"),
         plot_to_save, 
         width = 15, height = 40, device = cairo_pdf)
}

rank_all_samples_2cities_avg +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme()

```


And for all 50 cities:  

```{r, fig.align='center', fig.height=12, out.width='100%'}

rank_all_samples_avg <- ggplot(data = avg_by_city_and_firm, 
                               mapping = aes(x = rough_geodist, 
                                             y = avg_rank, 
                                             group = Sample,
                                             color = seg_color)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = avg_by_city, 
            mapping = aes(x = rough_geodist, 
                          y = avg_rank, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_y_reverse(breaks = c(1,5,10,15,20,25)) +
  scale_color_identity() +
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) +
  xlab("Distance in miles to the location of the law firm") +
  
  
  if(save == T){ 
    plot_to_save <- rank_all_samples_avg +
      facet_wrap(vars(City), ncol = 5)
    
    ggsave(here::here("plots",
                      "rank_all_samples_avg-50cities.pdf"),
           plot_to_save, 
           width = 15, height = 40, device = cairo_pdf)
  }

rank_all_samples_avg +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() + 
  theme(
    strip.text = element_text(size = 7.8,
                              color = "black",
                              face = "bold"),
    axis.line.x = element_line(color = "black",
                               size = .2),
    axis.line.y = element_line(color = "black",
                               size = .2),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 6,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.spacing.x = unit(0.2, "lines"), # less space around plots
    panel.spacing.y = unit(1, "lines"),
    axis.title.y.left = element_blank() # no axis label (the space is used by the plots instead)
  )
```


The average rank across all law firms is shown in pink. We see that the shape of the average rank by mile is similar between cities: it drops fast in the first mile, and then slowly stabilizes.   

It is computed with a rank of 25 for the firms out of the top 20 and for which the rank is not recorded anymore by Local Falcon. This is distorting the "true" average, which is unknown and likely lower at large miles. Another probable distortion is that the ranking is likely to "continuously" decline, and not stabilize at a certain value. The current impression of stabilization of the mean is due to the constant value of 25 attributed to the "+20" measurements. Nevertheless, our method allows for a visualization of an estimate of the average drop in each city. This estimate is just more precise for smaller distances.     



### Drop from Initial Position (Relative Ranking)

In order to better compare the drop in ranking between law firms and cities, we can visualize their drop from their initial position - the relative ranking. Note that this drop is still computed with a value of 25 for the "+20" measurements.   

First, for the most populated and less populated city:  


```{r fig.align='center', fig.height=4.5, out.width='100%'}

average_drop_2cities <- ggplot(data = two_cities, 
                               mapping = aes(
                                 x = rough_geodist, 
                                 y = avg_drop, 
                                 group = Sample)) +
  geom_line(alpha = 0.4) +
  geom_line(data = (avg_by_city %>% 
                      filter(City %in% c("New-York", "Oklahoma-City"))), 
            mapping = aes(x = rough_geodist, y = avg_drop, group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) + 
  labs(
    title = "The Drop in Ranking for Each Law Firm",
    subtitle = "Each grey line is a sample (a law firm), and their average is in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")


if(save == T){ 
  plot_to_save <- average_drop_2cities +
    facet_wrap(vars(City), ncol = 2) 
  
  ggsave(
    here::here("plots",
               "average_drop_2cities-50cities.pdf"),
    plot_to_save, 
    width = 15, height = 40, device = cairo_pdf)
}

average_drop_2cities +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme()

```


Then, for all 50 cities:  


```{r fig.align='center', fig.height=14, out.width='100%'}

average_drop_all_samples <- ggplot(data = avg_by_city_and_firm, 
                                   mapping = aes(x = rough_geodist, 
                                                 y = avg_drop, 
                                                 group = Sample)) +
  geom_line(alpha = 0.4) +
  # geom_point(alpha = 0.4, size = 0.2) +
  geom_line(data = avg_by_city, 
            mapping = aes(x = rough_geodist, 
                          y = avg_drop, 
                          group = 1), 
            size = 1.2, 
            color = r_col) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) +
  xlab("Distance in miles to the location of the law firm") +
  
  
  if(save == T){ 
    plot_to_save <- average_drop_all_samples +
      facet_wrap(vars(City), ncol = 5) 
    
    ggsave(
      here::here("plots",
                 "average_drop_all_samples-50cities.pdf"),
      plot_to_save, 
      width = 15, height = 40, device = cairo_pdf)
  }

average_drop_all_samples +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() +
  theme(
    strip.text = element_text(size = 7.8,
                              color = "black",
                              face = "bold"),
    axis.line.x = element_line(color = "black",
                               size = .2),
    axis.line.y = element_line(color = "black",
                               size = .2),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 6,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.spacing.x = unit(0.2, "lines"), # less space around plots
    panel.spacing.y = unit(1, "lines"),
    axis.title.y.left = element_blank() # no axis label (the space is used by the plots instead)
  )


```

The drop is always 0 at the location of the firms. We observe that the shape of the average drop, despite slight variations, is similar between cities.  

We can superimpose all the drops in one single plot to show **the average drop in ranking in relation to the distance from the location of a firm for each city**:  


```{r fig.align='center', fig.height=4.5, out.width='100%'}

library(ggiraph)

avg_drop_for_all_cities <- ggplot(data = avg_by_city) +
  geom_line_interactive(aes(x = rough_geodist,
                            y = avg_drop,
                            group = City,
                            tooltip = City,
                            data_id = City),
                        alpha = 1, color = r_col) +
  # geom_point(alpha = 0.4, size = 0.2) +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm$rough_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Average Drop by Mile in each City",
    subtitle = "Hover on a line to highlight a particular city"
  ) + 
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)") +
  geom_text_repel(
    aes(x = rough_geodist, y = avg_drop,  label = City), data = data_ends,
    fontface ="plain", 
    color = "black", 
    size = 3,
    # direction = "y"
  )

girafe(ggobj = avg_drop_for_all_cities,
       options = list(
         opts_hover_inv(css = "opacity:0.1;"),
         opts_hover(css = "stroke-width:2;")
       )
)
# x <- girafe(ggobj = gg)
# x <- girafe_options(x,
#                     opts_hover(
#                       css = "fill:wheat;stroke:blue;r:5pt;"),
#                     line = "fill:none;stroke:blue;stroke-width:3px"
# )
# if( interactive() ) print(x)

# if(save == T){ 
#   ggsave(
#     here::here("plots",
#                "avg_drop_for_all_cities-50cities.pdf"),
#     plot_to_save, 
#     width = 15, height = 15, device = cairo_pdf)
# }


```

Note that, again, the average is computed with a constant value of "25" for the samples out of the top 20. This explains the stabilization of the curve at large distances. Nevertheless, all cities see a drop of -5 to -12 in the average ranking of the law firms in the first mile. The drop seems to be larger in the Queens than in New Orleans.    


```{r include=FALSE}

#  average of the drop between all samples in all cities in a table:  

avg_by_city_and_firm %>% 
  group_by(rough_geodist) %>%
  summarise(average_drop = mean(avg_drop)) %>%
  select(`Distance to Firm (miles)` = rough_geodist, 
         `Average Cumulative Drop (position)` = average_drop) %>%
  kable(
    format = "html",
    digits = 1
  ) %>% 
  kable_styling(
    bootstrap_options = 'condensed',
    full_width = FALSE,
    position = 'center'
  )

```



### The Drop Follows a Rule of Exponential Decay

As we just saw, the drop in terms of ranking has a similar shape in all cities. The drop seems to follow more or less a rule of [exponential decay](https://en.wikipedia.org/wiki/Exponential_decay): it decreases at a rate proportional to its current value. At first, it decreases fast and then reaches stability.  

The _exponential decay function_ can be formalized like this:   

$Drop(d) = (Drop0 - DropFinal)* e^{-λd} + DropFinal$  

Where $Drop(d)$ is the drop at a distance $d$ and $λ$ is the decay constant. $Drop0$ is the intercept, the drop at distance 0. The parameter $DropFinal$ is included as a "correction" because we work with negative values (the drops in position are encoded as "-1", "-2", etc.).  

When fitting an _exponential decay function_ to the average, we estimate $λ$. If we have an estimate of $λ$, we can use the _exponential decay function_ to estimate the drop which would be expected, on average, at a certain distance $d$.  

We start by illustrating the decay with all the samples taken in all cities, together. In order to get a better estimate of the exponential decay function, we average the data each tenth of a mile. In pink, we see the average drop in ranking regardless of the city:   

````{r fig.align='center', fig.height=6, out.width='100%'}

avg_drop_total <- avg_by_city_and_firm_granular %>%
  group_by(granular_geodist) %>%
  summarise(avg_drop = mean(avg_drop))

# avg_drop_total_no_zero <- avg_drop_total %>%
#   mutate(granular_geodist = ifelse(granular_geodist == 0, 0.001, granular_geodist))

avg_drop_overall <- ggplot(data = avg_by_city_and_firm_granular, 
                           mapping = aes(x = granular_geodist, 
                                         y = avg_drop,
                                         group = unique_sample)) +
  geom_line(alpha = 0.1) +
  geom_line(data = avg_drop_total, 
            mapping = aes(x = granular_geodist, 
                          y = avg_drop, 
                          group = 1), 
            size = 0.2, 
            color = r_col) +
  geom_point(data = avg_drop_total, 
             mapping = aes(x = granular_geodist, 
                           y = avg_drop, 
                           group = 1), 
             size = 2, 
             color = r_col) +
  # geom_smooth(
  #   data = avg_drop_total_no_zero,
  #   mapping = aes(x = granular_geodist, 
  #                 y = avg_drop,
  #                 group = 1),
  #   
  #   method="glm", 
  #   formula = y ~ I(log(x)),
  #   se=FALSE, size=1, color = "#13D18F") +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm_granular$granular_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "The Average Drop, Over All 1100 Samples",
    subtitle = "Each grey line is a sample (a law firm), all cities included.\nMeasurement are binned each tenth of a mile.\nThe average is shown in pink."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")

avg_drop_overall

# if(save == T){ 
#   ggsave(
#     here::here("plots",
#                "avg_drop_overall-50cities.pdf"),
#     plot_to_save, 
#     width = 15, height = 15, device = cairo_pdf)
# }


```

Then we can fit an _exponential decay function_ to the average, in green:   


```{r fig.align='center', fig.height=8, out.width='100%'}

# fitting the exp decay:
y0 = max(avg_drop_total$avg_drop) # 0
yf = min(avg_drop_total$avg_drop) # ~-14
fit <- nls(avg_drop ~ yf + (y0 - yf) * exp(-alpha * granular_geodist), 
           data = avg_drop_total,
           start = list(y0 = y0, yf = yf, alpha = 2.2) # <- estimated initial value to ease fitting
)
# summary(fit)

# we can add the "fitted values" as a new column, 
# those are the value of the model at each distance.
avg_drop_total <- avg_drop_total %>%
  mutate(exp_decay_pred = predict(fit))

avg_drop_overall <- ggplot(data = avg_by_city_and_firm_granular, 
                           mapping = aes(x = granular_geodist, 
                                         y = avg_drop,
                                         group = unique_sample)) +
  geom_line(alpha = 0.1) +
  # the average in pink:
  geom_line(data = avg_drop_total,
            mapping = aes(x = granular_geodist,
                          y = avg_drop,
                          group = 1),
            size = 0.2,
            color = r_col) +
  geom_point(data = avg_drop_total, 
             mapping = aes(x = granular_geodist, 
                           y = avg_drop, 
                           group = 1), 
             size = 2, 
             color = r_col) +
  # the fit in green:
  geom_line(data = avg_drop_total, 
            mapping = aes(x = granular_geodist, 
                          y = exp_decay_pred, 
                          group = 1), 
            size = 1.5, 
            color = "#13D18F") +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm_granular$granular_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Average Drop Follows Exponential Decay Rule",
    subtitle = "Each grey line is a sample (a law firm), all cities included.\nMeasurement are binned each tenth of a mile.\nThe average is shown in pink and the exponential decay fit in green."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")

avg_drop_overall

```


An _exponential decay function_ fits the average drop very well. The _decay constant_ $λ$ estimated by the fit is `r round(coef(fit)[3],1)`. The other two constants are estimated as $Dropfinal$ = `r round(coef(fit)[2],1)` and $Drop0$ = `r round(coef(fit)[1],1)`. Note that the estimated drop at a distance of 0 mile is thus `r round(coef(fit)[1],1)`, which is not perfect as we know that it should be 0.   

We could use it to estimate the expected drop in ranking at any distance for an average law firm. For instance, the estimated drop at 1000 yards (0.59 mile) would be of $Drop(0.59) = (-2.1 + 11.9)* e^{-2.3 * 0.59}) - 11.9$ = -9.4 positions.  

This is just an estimate based on an average. We see on the plots above that in reality law firms drop following all sort of trajectories, as illustrated by the plot being "filled" by black lines between 0 and -20. Note also that the caveat of having imputed missing "+20" measurements with the constant value of 25 is impacting the average and thus the fit, especially the final stabilized value of -11.9 for the drop.  

Nevertheless, it is possible to fit such an exponential decay function separately for the averages in all cities. It would allow us to compute predictions of what the typical drop would look like in each city.     

For simplicity, here is the same plot showing only the average on all law firms and the _exponential decay_ fit:  

```{r fig.align='center', fig.height=6, out.width='100%'}

# (fit done in previous code chunk)

avg_drop_overall <- ggplot(data = avg_drop_total,
                           mapping = aes(x = granular_geodist,
                                         y = avg_drop,
                                         group = 1)) +
  # the average in pink:
  geom_line(size = 0.2,
            color = r_col) +
  geom_point(size = 1, 
             color = r_col) +
  # the fit in green:
  geom_line(data = avg_drop_total, 
            mapping = aes(x = granular_geodist, 
                          y = exp_decay_pred, 
                          group = 1), 
            size = 1.5, 
            color = "#13D18F") +
  scale_x_continuous(
    breaks = seq(0, max(avg_by_city_and_firm_granular$granular_geodist), by = 2), 
    minor_breaks = NULL) +
  my_theme() +
  labs(
    title = "Average Drop Follows Exponential Decay Rule",
    subtitle = "The average drop (across all firms and cities) is shown in pink,\nand the exponential decay fit in green."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Drop in the ranking\n(indexed at 0)")

avg_drop_overall

```



```{r, include=FALSE}
# Experimenting with fitting the decay:

# # normalize btw 20 and 0:
# data_for_fit <- avg_drop_total_no_zero %>%
#   mutate(
#     avg_drop_norm = 0 + (((avg_drop - min(avg_drop)) * (20 - 0))  / (max(avg_drop) - min(avg_drop))),
#     avg_drop_translatd = avg_drop + 20
#   ) 
# 
# data_for_fit <- avg_drop_total %>%
#   mutate(
#     avg_drop_norm =avg_drop,
#     avg_drop_translatd = avg_drop
#   )
# 
# # linearizing:
# fit1 = lm(avg_drop_translatd ~ granular_geodist, data = data_for_fit)
# summary(fit1)
# 
# # exp decay
# y0 = min(data_for_fit$avg_drop_translatd)
# yf = max(data_for_fit$avg_drop_translatd)
# fit2 <- nls(avg_drop_translatd ~ yf + (y0 - yf) * exp(-alpha * granular_geodist), 
#             data = data_for_fit,
#             start = list(y0 = y0, yf = yf, alpha = 5),
# )
# summary(fit2)
# 
# # asymptotic regression function (a self-starting function):
# fit3 <- nls(avg_drop_translatd ~ SSasymp(granular_geodist, yf, y0, log_alpha), data = data_for_fit)
# summary(fit3)
# 
# 
# 
# tmp <- data_for_fit %>%
#   mutate(
#     pred1 = predict(fit1),
#     pred2 = predict(fit2),
#     pred3 = predict(fit3)
#   )
# 
# ggplot(tmp, aes(x=granular_geodist, y = avg_drop_translatd)) +
#   geom_line(color = r_col) +
#   geom_line(aes(x=granular_geodist, y = pred1), color = "red") +
#   geom_line(aes(x=granular_geodist, y = pred2), color = "blue", linetype = "dashed", size=3) +
#   geom_line(aes(x=granular_geodist, y = pred3), color = "orange", linetype = "dashed") +
#   stat_smooth(method = "nls", formula = y ~ SSasymp(x, Asym, R0, lrc), se = FALSE, color = "black", linetype = "dashed") +
#   geom_smooth( 
#     method="glm", 
#     formula = y ~ I(log(x)),
#     se=FALSE, size=1, color = "#13D18F", linetype = "dashed") +
#   theme_minimal()


```


```{r include=FALSE}
#  average of the drop between all samples in all cities in a table:  
avg_by_city_and_firm %>% 
  group_by(rough_geodist) %>%
  summarise(average_drop = mean(avg_drop)) %>%
  select(`Distance to Firm (miles)` = rough_geodist, 
         `Average Cumulative Drop (position)` = average_drop) %>%
  kable(
    format = "html",
    digits = 1
  ) %>% 
  kable_styling(
    bootstrap_options = 'condensed',
    full_width = FALSE,
    position = 'center'
  )

# Used this to determine the average drop in the first mile: ~-8 positions. 

```


## When are Law Firms Dropping Out of the Top 20?

Google Maps shows 20 results on the first search page and Local Falcon does not collect the ranking above the top 20. We saw above that the ranking was dropping fast in the first mile, but also that not all the firms were dropping out of the top 20 after 10 miles. And this, in all cities, regardless of their area.  

For example, a 10-mile radius is enough to completely cover the city of Boston and its surroundings, but this is absolutely not the case in Los Angeles. However, in both cases, we identify companies that fall out of the top 20 after 5 or 10 miles and others that do not fall out of the top 20.  

**How does the proportion of law firms out of the top 20 change with distance?**   

We first have a look at New-York and Oklahoma-City:  

```{r fig.align='center', fig.height=4.5, out.width='100%'}

two_cities_no_firms <- avg_by_city %>% 
  filter(City %in% c("New-York", "Oklahoma-City")) %>%
  # mutate(avg_rank = ifelse(avg_rank == 21, NA, avg_rank)) %>%
  droplevels()

perc_out_of_top20_two_cities <- ggplot(data = two_cities_no_firms, 
                                       mapping = aes(x = rough_geodist, 
                                                     y = percentage_out_of_top20, 
                                                     group = 1)) +
  geom_point(size = 0.4) +
  geom_line() +
  geom_area(alpha = 0.3, fill = r_col) + 
  facet_wrap(vars(City), ncol = 5) + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city$rough_geodist), by = 2), 
    minor_breaks = NULL 
  ) + 
  coord_cartesian(clip = "off") +
  labs(
    title = "Percentage of the Firms Out of the Top 20, by Mile",
    subtitle = "In New York, 80% of the law firms rank out of the top 20 after 10 miles.\nThis is far to be the case in Oklahoma City."
  ) +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Percentage of the firms\nout of the top 20") + 
  geom_text_repel(
    aes(x = rough_geodist, 
        y = percentage_out_of_top20,  
        label = paste0(as.character(round(100*percentage_out_of_top20,0)),"%")
    ), 
    data = data_ends %>% filter(City %in% c("New-York", "Oklahoma-City")),
    fontface ="plain", 
    color = "black", 
    size = 3,
    # nudge_y = 0.01,
    min.segment.length = 5,
    direction = "y",
    xlim = c(14.2,18)
  )

# average_drop

if(save == T){ 
  plot_to_save <- perc_out_of_top20_two_cities +
    facet_wrap(vars(City), ncol = 2) +
    ylab("Percentage of the firms\nout of the top 20")
  
  ggsave(here::here("plots",
                    "perc_out_of_top20_two_cities-50cities.pdf"),
         perc_out_of_top20_two_cities, 
         width = 15, 
         height = 8, 
         device = cairo_pdf)
}

perc_out_of_top20_two_cities +
  facet_wrap(vars(City), ncol = 2) + 
  my_theme() 


```

There is a radical difference here. The percentage of law firms that dropped out of the top 20 rises to 80% in New York, after around 10 miles. Whereas in Oklahoma city, this number never rises above 30%; a larger proportion of law firms rank well, even at large distances.   

The same figure, for all the 50 largest U.S. cities:  

```{r fig.align='center', fig.height=13, out.width='100%'}

perc_out_of_top20 <- ggplot(data = avg_by_city, 
                            mapping = aes(x = rough_geodist, 
                                          y = percentage_out_of_top20, 
                                          group = 1)) +
  # geom_point(size = 0.2) +
  geom_line() +
  geom_area(alpha = 0.3, fill = r_col) + 
  facet_wrap(vars(City), ncol = 5) + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(
    breaks = seq(0,max(avg_by_city$rough_geodist), by = 5), 
    minor_breaks = NULL 
  ) + 
  coord_cartesian(xlim = c(0, 16), clip = "off") + # for the labels to the right
  labs(
    title = "Percentage of the Firms Out of the Top 20, by Mile") +
  xlab("Distance in miles to the location of the law firm") +
  ylab("Percentage of the firms out of the top 20") + 
  geom_text_repel(
    aes(x = rough_geodist, 
        y = percentage_out_of_top20,  
        label = paste0(as.character(round(100*percentage_out_of_top20,0)),"%")
    ), 
    data = data_ends,
    fontface ="bold", 
    color = "black", 
    size = 2.5,
    direction = "y",
    min.segment.length = 2,
    xlim = c(15,20)
  )

# average_drop

# if(save == T){ 
#   plot_to_save <- perc_out_of_top20 +
#     facet_wrap(vars(City), ncol = 5) +
#     ylab("Percentage of the firms\nout of the top 20")
#   
#   ggsave(here::here("plots",
#                     "perc_out_of_top20-50cities.pdf"),
#          perc_out_of_top20, 
#          width = 15, 
#          height = 8, 
#          device = cairo_pdf)
# }

perc_out_of_top20 +
  facet_wrap(vars(City), ncol = 5) + 
  my_theme() +
  theme(
    strip.text = element_text(size = 7.8,
                              color = "black",
                              face = "bold"),
    axis.line.x = element_line(color = "black",
                               size = .2),
    axis.line.y = element_line(color = "black",
                               size = .2),
    axis.title.x = element_text(size = 11,
                                face = "bold"),
    axis.title.y = element_text(size = 11,
                                face = "bold"),
    axis.text = element_text(size = 7,
                             color = "black",
                             face = "bold"),
    axis.ticks = element_blank(),
    panel.grid.major.x = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.major.y = element_line(size = .2,
                                      color = "#eaeaea",
                                      linetype = "solid"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
  )


```

The percentage of law firms that dropped out of the top 20 at the largest distance ranges from 27% in Pittsburgh to 92% in Queens. 

The cities are ordered by population size. It seems that the percentage of law firms that are able to remain in the top 20 is lower in the largest cities.    

__This measure is likely an estimate of the competition in each city.__   

Note that these percentages are computed on 20 sample law firms. Please note also that the largest distance is not exactly the same in all cities. These differences are due to the precision of Local Falcon, geolocalization, and computation of geographical distance from coordinates. 






# Summary and Key Observations

We sampled 20 personal injury law firms in the 50 largest U.S. cities. For each, we measured their ranking for the keyword "car accident lawyer" at 225 locations disposed on a squared grid of 10 miles "radius" around the original location of the firm, using Local Falcon (+ 10 samples with a radius of 5 miles for the 10 largest cities).   

We then compute the rankings and relative ranking (drop) of each law firm for each mile away from its location, as well as the percentage of the firms dropping out of the top 20 positions.  

## Key Observations 

1. __The ranking drops dramatically in the first mile__; in all cities. On average, the drop in ranking in the first mile is -8 positions.   

2. __The drop in ranking varies greatly between law firms. Some top-ranking firms do not even see a drop__ in the 10-mile radius. This means that there is probably no distance that would guarantee that all of the law firms in a given city drop out of the top 20. __On the other hand, some law firms drop very quickly out of the top 20__. Often, these are firms that already did not rank 1st at their own location.        

3. After the quick drop, the average ranking stabilizes or decreases much slower. This effect is partly due to observation 2: we compute an average between law firms still ranking well and law firms which ranking is imputed to 25 because they are out of the top 20. This effect, albeit with some slight variations, is seen in all cities.  

4. This drop in the ranking is following an _exponential decay rule_, and this rule could be used to estimate the expected drop for any firm in any city at any distance. Caveats: in reality, the variance between the law firms is very large and this just an estimate of their average. Furthermore, this rule is based on imputing the value 25 to the "+20" ranks.         

5. __The percentage of law firms that dropped out of the top 20 for each mile distance varies a lot between cities__. In most cities, the largest increase of law firms dropping out of the top 20 is taking place in the first mile. The maximum of companies out of the top 20 varies dramatically between cities, ranging from 27% in Pittsburgh to 92% in Queens. These percentages can be used to estimate the probability of a law firm to rank in (or out) of the top 20 in each city, at each mile. __These results are likely a reflection of the competition among personal injury lawyers in each city__.   

All these observations might have an impact on the current Rankings.io offer of a 5-mile geographic radius around a client’s headquarters to take more than one client in larger cities. They also show the benefit of opening several offices in large cities, as the ranking is dropping fast by distance.    



